'''
Description of the program:
---------------------------
Provided that there are data generated by a Monte Carlo simulation (meaning one raw_data file for each beta that each consists of all the measurements) either with the Wolff or the Metropolis algorithm for the Ising Model, this progam aims at
calcuating the values of the partition function Z_i for the discrete beta_i values (i=1,...,n) that were used in the Monte Carlo simulations.
Calculating Z_i is the first step of calculating interpolated values of a certain physical quantity Q of the system using the multiple histogram method.
The two response functions are c (specific heat) and chi (magnetic susceptibility).

Required data:
--------------
One run of either the Metrpolis or the Wolff algorithm for a fixed number of lattice sites N delivers a set of different measurements of internal energies u_j and magnetizations m_j (j=1,...,p) for one specific beta_i (i=1,...,n).
Hereby p is the total number of taken measurements for one beta, n is the number of different beta.
These are the raw data that are returned by either the Metropolis of the Wolff algorithm. All results have to be put into one csv file ("_reprocessed_ising_wolf.csv") with the following structure:
n;interpol_E;interpol_M;beta;J;B;N
Hereby, J is the spin coupling of the Ising Model, B the magnetic field, N the number of sites, n the iteration step of the Monte Carlo algorithm,
interpol_E and interpol_M are the measured values during the Monte Carlo simulation that serve as basis for the interpolation.
If the names of the columns are changed, the program won't work, therefore, keeping the same column names is important.

Putting all the data of the raw_data files into the "_reprocessed_data_wolf.csv" file can be done using the "combine_csv_reprocessed.py" script.

Literature:
-----------
M.E.J. Newman and G.T. Barkema. Monte Carlo Methods in Statistical Physics. Clarendon Press Oxford, 1999.
(There is an entire chapter on the multiple histogram method.)
'''


import numpy as np
import pandas as pd
import numba
import os
import sys
import torch
import datetime as dt

# Provide the source to the data csv file as describd in the header.
reprocessed_source=sys.argv[1]
df=pd.read_csv(reprocessed_source, sep=';')

# Alter the elements of the list so that it suits the list of beta values that the Monte Carlo algorithm was run for.
_beta=np.array([0.25, 0.275, 0.3, 0.325, 0.35, 0.375, 0.4, 0.425, 0.45, 0.475, 0.5, 0.525, 0.55, 0.575, 0.6])
_N=df['N'].unique()
# Provide the number of lattice sites that Monte Carlo simulations were run on (as in the csv file).
_N=np.array([25,100,225,400,900])
_beta_len=(_beta.shape[0])

# n_block=number of iterations per beta - cut off (thermalization); this equals the number of values p for u and m
n_block=9800
_N_len=(_N.shape[0])
# initialize array
energy=np.zeros((_N_len,_beta_len,n_block))
magnetization=np.zeros((_N_len,_beta_len,n_block))

# Iitialization function that creates the arrays to store.
def init_arr():
    meta=np.ones((_beta_len,3)) # Stores the number of measurements, partition function Z, beta.
    meta_tot=np.ones((_N_len,_beta_len,3)) # Stores the tuple number of measurements, partition function Z, beta for each number of sites N.

    #Initializing the arrays
    j=-1
    # Initializing the arrays that are needed for the approximation of the partition functions.
    for N in _N:    # Running over all the different lattice sizes N.
        j=j+1
        i=-1
        for beta in _beta: # Running over all the different inverse temperatures beta.
            i=i+1

            # Preparing the meta_tot array.
            # meta stores the row values of meta_tot.
            meta[i,2]=beta
            tmp=df.loc[(df['beta']==beta) & (df['N']==N)]   # Get the number of independet measurements.
            meta[i,0]=tmp.shape[0]
            meta[i,1]=1                                     # Assign initial value of Z.
            # Prepare the energy array:
            tmp_energy=df.loc[(df['beta']==beta) & (df['N']==N)]
            np_tmp_energy=tmp_energy['mu_E'].to_numpy()

            # Prepare chi array:
            tmp_magnetization=df.loc[(df['beta']==beta) & (df['N']==N)]
            np_tmp_magnetization=tmp_magnetization['mu_M'].to_numpy()

            # Writing energy and chi in to the energy and chi array:
            for z in range (0,n_block):
                energy[j,i,z]=np_tmp_energy[z]*N  # Multiplication with N to make it extensive, necessary to do the interpolation.
                magnetization[j,i,z]=np.abs(np_tmp_magnetization[z])*N  # Multiplication with N to make it extensive, necessary to do the interpolation.
        meta_tot[j]=meta
    return meta_tot

# Calculate the partition functions for each beta_i.
# This function simply implements the iterative formula that Newman et al. introduce (Newman et al., p. 227).
@numba.njit     # Used for the acceleration of the paython loops.
def calculate(meta_tot):
    A=np.array([1.0])
    delta=np.ones(5)
    N=-1
    for l in _N:
        N=N+1
        n_iterations=1000
        for it in range(0,n_iterations):
            tmp=np.zeros(_beta_len)
            A=1/(np.sqrt(np.min(meta_tot[N,:,1])*np.max(meta_tot[N,:,1])))
            meta_tot[N,:,1]=A*meta_tot[N,:,1]
            for k in range(0,_beta_len):
                for i in range(0,_beta_len):     # looping over all simulations = beta values
                    for s in range(0,n_block):   # looping ofer all states
                        denominator=np.array([0.0])
                        for j in range(0,_beta_len):
                            denominator=denominator+meta_tot[N,j,0]*(1/meta_tot[N,j,1])*np.exp((meta_tot[N,k,2]-meta_tot[N,j,2])*energy[N,i,s])
                        tmp[k]=tmp[k]+1/denominator[0]
            delta[N]=np.sum(((tmp-meta_tot[N,:,1])/tmp)**2)
            meta_tot[N,:,1]=tmp
            # convergence condition
            if delta[N] <=1e-7:
                break
    return meta_tot, delta


# main function
def main():
    # Initialize the array that stores the partition functions.
    tmp_meta_tot=init_arr()
    # Do the calculations of the partition function and print them in the terminal.
    final_meta_tot, delta=calculate(tmp_meta_tot)
    print('Here are the results for the partition functions: ')
    print(final_meta_tot)
    # The results must be copied and stored in a "Z_beta_N=##.csv" file in which the number of sites N must be correctly inserted. A dummy file is in the repository.
    print('These are the deltas: ')
    # Print the error to see how good the convergence is.
    print(delta)

if __name__ == '__main__':
    main()
